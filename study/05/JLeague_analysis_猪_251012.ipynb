{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベースラインのコード\n",
    "- （2025年10月12日時点）猪メモ\n",
    "- 特徴量エンジニアリングはmake_features関数を参照\n",
    "- 現時点での最高スコアは、勾配木回帰（GradientBoosting）を用いた「3633.772917813335」\n",
    "- いろんな仮説に基づく特徴量は入れ込めていないが一旦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\n-kozuma\\\\program_files\\\\90_JLeague\\\\input_data\\\\train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     37\u001b[39m plt.rcParams[\u001b[33m'\u001b[39m\u001b[33maxes.linewidth\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m1.2\u001b[39m \n\u001b[32m     39\u001b[39m pref_list = [\n\u001b[32m     40\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m北海道\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m青森県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m岩手県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m宮城県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m秋田県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m山形県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m福島県\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m茨城県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m栃木県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m群馬県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m埼玉県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m千葉県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m東京都\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m神奈川県\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m熊本県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m大分県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m宮崎県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m鹿児島県\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m沖縄県\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     47\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m train = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mR\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mn-kozuma\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mprogram_files\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m90_JLeague\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43minput_data\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mtrain.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#学習用試合データ\u001b[39;00m\n\u001b[32m     50\u001b[39m train_add = pd.read_csv(\u001b[33mR\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn-kozuma\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mprogram_files\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m90_JLeague\u001b[39m\u001b[33m\\\u001b[39m\u001b[33minput_data\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mtrain_add.csv\u001b[39m\u001b[33m\"\u001b[39m, sep=\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m, header=\u001b[32m0\u001b[39m, quotechar=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m\"\u001b[39m)\u001b[38;5;66;03m#学習用試合追加データ\u001b[39;00m\n\u001b[32m     51\u001b[39m condition = pd.read_csv(\u001b[33mR\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn-kozuma\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mprogram_files\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m90_JLeague\u001b[39m\u001b[33m\\\u001b[39m\u001b[33minput_data\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcondition.csv\u001b[39m\u001b[33m\"\u001b[39m, sep=\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m, header=\u001b[32m0\u001b[39m, quotechar=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m\"\u001b[39m)\u001b[38;5;66;03m#試合詳細データ\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\dsclass\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\dsclass\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\dsclass\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\dsclass\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\dsclass\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\n-kozuma\\\\program_files\\\\90_JLeague\\\\input_data\\\\train.csv'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib import font_manager as fm\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, ElasticNet,HuberRegressor, TheilSenRegressor, QuantileRegressor)\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "fm._load_fontmanager(try_read_cache=False)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=600, threshold=np.inf,floatmode=\"fixed\")\n",
    "plt.rcdefaults()\n",
    "sns.set_style(\"whitegrid\") \n",
    "plt.rcParams['font.family'] = 'IPAexGothic'\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['axes.labelsize'] = 8 \n",
    "plt.rcParams['axes.titlesize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "plt.rcParams['ytick.labelsize'] = 8\n",
    "plt.rcParams['figure.figsize'] = (8, 3) \n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "plt.rcParams['axes.linewidth'] = 1.2 \n",
    "\n",
    "pref_list = [\n",
    "    \"北海道\",\"青森県\",\"岩手県\",\"宮城県\",\"秋田県\",\"山形県\",\"福島県\",\n",
    "    \"茨城県\",\"栃木県\",\"群馬県\",\"埼玉県\",\"千葉県\",\"東京都\",\"神奈川県\",\n",
    "    \"新潟県\",\"富山県\",\"石川県\",\"福井県\",\"山梨県\",\"長野県\",\"岐阜県\",\n",
    "    \"静岡県\",\"愛知県\",\"三重県\",\"滋賀県\",\"京都府\",\"大阪府\",\"兵庫県\",\n",
    "    \"奈良県\",\"和歌山県\",\"鳥取県\",\"島根県\",\"岡山県\",\"広島県\",\"山口県\",\n",
    "    \"徳島県\",\"香川県\",\"愛媛県\",\"高知県\",\"福岡県\",\"佐賀県\",\"長崎県\",\n",
    "    \"熊本県\",\"大分県\",\"宮崎県\",\"鹿児島県\",\"沖縄県\"\n",
    "]\n",
    "\n",
    "train = pd.read_csv(\"../input_data/jleague/train.csv\", sep=\",\", header=0, quotechar=\"\\\"\")#学習用試合データ\n",
    "train_add = pd.read_csv(\"../input_data/jleague/train_add.csv\", sep=\",\", header=0, quotechar=\"\\\"\")#学習用試合追加データ\n",
    "condition = pd.read_csv(\"../input_data/jleague/condition.csv\", sep=\",\", header=0, quotechar=\"\\\"\")#試合詳細データ\n",
    "condition_add = pd.read_csv(\"../input_data/jleague/condition_add.csv\", sep=\",\", header=0, quotechar=\"\\\"\")#試合詳細追加データ\n",
    "stadium = pd.read_csv(\"../input_data/jleague/stadium.csv\", sep=\",\", header=0, quotechar=\"\\\"\")#スタジアムデータ\n",
    "test = pd.read_csv(\"../input_data/jleague/test.csv\", sep=\",\", header=0, quotechar=\"\\\"\")#評価用試合データ\n",
    "\n",
    "# これは何に使うんだ...？？\n",
    "add_2014 = pd.read_csv(\"../input_data/jleague/2014_add.csv\", sep=\",\", header=0, quotechar=\"\\\"\")  #2014年度後半試合追加データ。2014年後半の38件の対戦データ。あくまで補足データである。得点が含まれているため、モデル検証用データと組み合わせることで、その対戦時にチームが現在何位なのかが分かる\n",
    "\n",
    "\n",
    "# マージする\n",
    "# stadium：収容人数・所在地\n",
    "# condition：スコア、天気、温度、湿度、レフリー、ホームチーム名、選手11人、アウェイチーム名、選手11人、\n",
    "train_df = pd.concat([train, train_add], axis=0, ignore_index=True)\n",
    "train_df = pd.merge(train_df, stadium, how=\"left\", left_on=\"stadium\", right_on=\"name\")\n",
    "condition_df = pd.concat([condition, condition_add], axis=0, ignore_index=True)\n",
    "train_df = pd.merge(train_df, condition_df, how=\"left\", on=\"id\")\n",
    "\n",
    "test_df = pd.merge(test, stadium, how=\"left\", left_on=\"stadium\", right_on=\"name\")\n",
    "test_df = pd.merge(test_df, condition_df, how=\"left\", on=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(data):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # y=0のデータを削除して、y_capa_ratioを出す。\n",
    "    if \"y\" in df.columns:\n",
    "        df = df[df[\"y\"] > 0].reset_index(drop=True)\n",
    "        df[\"y_capa_ratio\"] = df[\"y\"] / df[\"capa\"]\n",
    "        df[\"y_capa_ratio_log\"] = np.log1p(df[\"y_capa_ratio\"])\n",
    "    \n",
    "    # 「ザスパ草津」を「ザスパクサツ群馬」にする。\n",
    "    df[[\"home\", \"away\"]] = df[[\"home\", \"away\"]].replace(\"ザスパ草津\", \"ザスパクサツ群馬\")\n",
    "    \n",
    "    # 選手名（home_01～home_11、away_01～away_11）を削除。一旦利用しない。\n",
    "    df = df.drop(columns=[f\"home_{str(i).zfill(2)}\" for i in range(1, 12)] + [f\"away_{str(i).zfill(2)}\" for i in range(1, 12)])\n",
    "    \n",
    "    # idとrefereeも削除。一旦利用しない。\n",
    "    df = df.drop(columns=[\"id\", \"referee\"])\n",
    "    \n",
    "    # addressから都道府県名を抽出。\n",
    "    df[\"prefecture\"] = df[\"address\"].apply(lambda x: next((pref for pref in pref_list if pref in x), np.nan))\n",
    "    df = df.drop(columns=[\"address\"])\n",
    "    \n",
    "    # home_team\taway_teamは重複しているので削除\n",
    "    df = df.drop(columns=[\"home_team\", \"away_team\"])\n",
    "    \n",
    "    \n",
    "\n",
    "    # 湿度と温度から不快指数を作成する。\n",
    "    df[\"humidity_num\"] = df[\"humidity\"].str.replace(\"%\",\"\").astype(\"float\")\n",
    "    df[\"discomfort_index\"] = 0.81 * df[\"temperature\"].astype(\"float\") + 0.01 * df[\"humidity_num\"] * (0.99 * df[\"temperature\"].astype(\"float\") - 14.3) + 46.3 \n",
    "    df[\"discomfort_category\"] = pd.cut(df[\"discomfort_index\"], bins=[0, 60, 75,100], labels=[\"寒い\", \"普通\", \"暑い\"])\n",
    "    df = df.drop(columns=[\"humidity\",\"temperature\",\"humidity_num\",\"discomfort_index\"])\n",
    "    \n",
    "    # match（第１節第２日）から、数字をそれぞれ抜き出す。\n",
    "    # round（節）は、35-42を1つのカテゴリとする。なぜならここはJ2しかないので。残りは同じ幅で区分する\n",
    "    df[\"round\"] = df[\"match\"].str.extract(r\"第(\\d+)節\")[0].astype(int).astype(str)\n",
    "    # df[\"round_cat\"] = pd.cut(df[\"round\"], bins=[0, 7, 14, 21, 28, 34, 42], labels=[\"1-7\", \"8-14\", \"15-21\", \"22-28\", \"29-34\", \"35-42\"])\n",
    "    # df[\"round_day\"]   = df[\"match\"].str.extract(r\"第(\\d+)日\")[0].astype(int).astype(str)\n",
    "    df = df.drop(columns=[\"match\"])\n",
    "\n",
    "    # J1フラグ\n",
    "    df[\"J1_flg\"] = df[\"stage\"].apply(lambda x: 1 if x==\"Ｊ１\" else 0)\n",
    "\n",
    "    # 日時系統\n",
    "    df[\"date\"] = pd.to_datetime(df[\"year\"].astype(str) + \"-\" + df[\"gameday\"].str.extract(r\"(\\d+/\\d+)\")[0],format=\"%Y-%m/%d\", errors=\"coerce\")\n",
    "    df[\"month\"] = df[\"gameday\"].apply(lambda x: int(x.split(\"/\")[0]))\n",
    "    df[\"day\"] = df[\"gameday\"].apply(lambda x: int(x.split(\"/\")[1].split(\"(\")[0]))\n",
    "    df[\"weekday\"] = df[\"gameday\"].apply(lambda x: x.split(\"(\")[1].replace(\")\",\"\"))\n",
    "    df[\"hour\"] = df[\"time\"].apply(lambda x: int(x.split(\":\")[0]))\n",
    "    df[\"hour_category\"] = pd.cut(df[\"hour\"], bins=[0, 14, 17, 24], labels=[\"afternoon\", \"evening\", \"night\"])\n",
    "    df[\"is_weekend\"] = df[\"gameday\"].str.contains(\"[土日祝]\").astype(int)\n",
    "    df[\"season\"] = pd.cut(df[\"month\"],bins=[0, 3, 6, 9, 12],labels=[\"winter\", \"spring\", \"summer\", \"autumn\"])\n",
    "    df[\"December_flg\"] = (df[\"month\"] == 12).astype(int)\n",
    "    \n",
    "    # 日時系は削除 yearはtestデータでは2014年のみなので削除\n",
    "    df = df.drop(columns=[\"date\",\"time\",\"year\",\"weekday\",\"hour\",\"month\",\"day\"])\n",
    "\n",
    "    # TV放送数\n",
    "    df[\"tv_N\"] = df[\"tv\"].apply(lambda x: len(x.split(\"／\")))\n",
    "    # NHKフラグ\n",
    "    df[\"tv_NHK_flg\"] = df[\"tv\"].apply(lambda x: 1 if \"ＮＨＫ\" in x else 0)\n",
    "    \n",
    "    # 有料無料フラグ。有料チャンネルだけから構成される →「有料」\n",
    "    paid_channels = [\"スカパー\", \"ｅ２\"]\n",
    "    df[\"tv_paid\"] = (df[\"tv\"].str.split(\"／\").apply(lambda lst: int(all(any(k in ch for k in paid_channels) for ch in lst))))\n",
    "    \n",
    "    df = df.drop(columns=[\"tv\"])\n",
    "    # 天気\n",
    "    df[\"weather_cat\"] = df[\"weather\"].apply(lambda x: x[0])\n",
    "    df = df.drop(columns=[\"weather\"])\n",
    "    \n",
    "    # season、hour_category、weather_catを結合したカラムを作成\n",
    "    df[\"season_hour_weather\"] = df[\"season\"].astype(str) + \"_\" + df[\"hour_category\"].astype(str) + \"_\" + df[\"weather_cat\"].astype(str)\n",
    "    df = df.drop(columns=[\"season\",\"hour_category\",\"weather_cat\"])\n",
    "    \n",
    "    # home_scoreとaway_scoreとの差分を考える。絶対値にする。あんまり差がありすぎると面白くないので少ないのでは？という\n",
    "    df[\"score_diff\"] = abs(df[\"home_score\"] - df[\"away_score\"])\n",
    "    df = df.drop(columns=[\"home_score\",\"away_score\"])\n",
    "\n",
    "    df = df.drop(columns=[\"name\",\"gameday\"])\n",
    "    return df\n",
    "\n",
    "train_df_processed = make_features(train_df)\n",
    "display(train_df_processed.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['y','y_capa_ratio','y_capa_ratio_log', 'capa']\n",
    "feature_cols = [c for c in train_df_processed.columns if c not in drop_cols]\n",
    "X = train_df_processed[feature_cols]\n",
    "y = train_df_processed['y_capa_ratio_log']\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = [c for c in X.columns if c not in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリ変数はTarget Encoding。数値は何もしない。\n",
    "def make_preprocess():\n",
    "    return ColumnTransformer(transformers=[\n",
    "        ('target_encoder',TargetEncoder(categories='auto', target_type='continuous',smooth='auto', cv=5, shuffle=True, random_state=42), categorical_cols),\n",
    "        ('num', 'passthrough', num_cols)])\n",
    "\n",
    "def make_pipeline(model):\n",
    "    return Pipeline([\n",
    "        ('preprocess', make_preprocess()),\n",
    "        ('model', model),\n",
    "    ])\n",
    "\n",
    "# 色々なモデルを試してみる\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"Lasso\": Lasso(alpha=0.1, max_iter=10000, random_state=42),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=10000, random_state=42),\n",
    "    \"HuberRegressor\": HuberRegressor(max_iter=10000, epsilon=1.35), \n",
    "    \"TheilSenRegressor\": TheilSenRegressor(random_state=42, max_subpopulation=10000),\n",
    "    \"QuantileRegressor\": QuantileRegressor(quantile=0.5, alpha=0.01, solver=\"highs\"),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=200, max_depth=5, min_samples_leaf=10,max_features=\"sqrt\", random_state=42, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, max_depth=3,min_samples_leaf=10, subsample=0.8, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=3,subsample=0.8, colsample_bytree=0.8,random_state=42, verbosity=0),\n",
    "    \"LightGBM\": LGBMRegressor(n_estimators=300, learning_rate=0.1, max_depth=5,subsample=0.8, colsample_bytree=0.8,random_state=42,verbosity=-1),\n",
    "    \"CatBoost\": CatBoostRegressor(iterations=300, learning_rate=0.05, depth=4,random_seed=42, verbose=False),\n",
    "    \"SVR\": SVR(C=1.0, epsilon=0.2, kernel=\"rbf\"),\n",
    "    \"KNN\": KNeighborsRegressor(n_neighbors=5)\n",
    "}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pipeline = make_pipeline(model)\n",
    "    scores = cross_val_score(pipeline, X, y, scoring=\"neg_root_mean_squared_error\", cv=kf)\n",
    "    rmse_mean = -scores.mean()\n",
    "    results[name] = rmse_mean\n",
    "\n",
    "results_df = pd.DataFrame(list(results.items()), columns=['モデル', '平均RMSE']).sort_values(by='平均RMSE')\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"XGBoost\"\n",
    "final_model = models[model_name]\n",
    "final_pipeline = make_pipeline(final_model)\n",
    "final_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量エンジニアリングを同じように実施\n",
    "test_df_processed = make_features(test_df)\n",
    "X_test = test_df_processed[feature_cols]\n",
    "display(X_test.shape)\n",
    "y_pred_log_ratio = final_pipeline.predict(X_test)\n",
    "\n",
    "# 数値安定化（オーバーフロー・NaN対策）\n",
    "y_pred_log_ratio = np.nan_to_num(y_pred_log_ratio, neginf=-20.0, posinf=20.0)\n",
    "y_pred_log_ratio = np.clip(y_pred_log_ratio, -20.0, 20.0)\n",
    "\n",
    "ratio_hat = np.expm1(y_pred_log_ratio)\n",
    "ratio_hat = np.clip(ratio_hat, 0.0, 1.0)\n",
    "\n",
    "# 人数へ変換し、キャパで上限\n",
    "y_capa = test_df_processed[\"capa\"].astype(float).to_numpy()\n",
    "y_pred_test_final = ratio_hat * y_capa\n",
    "y_pred_test_final = np.minimum(y_pred_test_final, y_capa)\n",
    "\n",
    "y_pred_test_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提出ファイル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = test_df[[\"id\"]].copy()\n",
    "submit[\"pred\"] = y_pred_test_final\n",
    "time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "#submit.to_csv(f\"C:\\\\Users\\\\n-kozuma\\\\program_files\\\\90_JLeague\\\\submit\\\\submit_{model_name}_{time}.csv\",  sep=\",\", index=False, header=False)\n",
    "print(f\"submit_{model_name}_{time}.csv\")\n",
    "\n",
    "display(submit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
