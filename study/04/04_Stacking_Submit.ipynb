{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "　スタッキングの実装例. 適用方法1で投稿ファイル作成まで."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "input_path = \"../input_data/\"\n",
    "\n",
    "# Set Display Max Columns\n",
    "pd.set_option(\"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data and Make Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    input_path + \"bank/train.csv\",\n",
    "    sep = \",\",\n",
    "    header = 0,\n",
    "    quotechar = \"\\\"\"\n",
    ")\n",
    "train_x = train[[\"age\", \"duration\", \"campaign\"]].copy()\n",
    "train_y = train[[\"y\"]].copy()\n",
    "\n",
    "test = pd.read_csv(\n",
    "    input_path + \"bank/test.csv\",\n",
    "    sep = \",\",\n",
    "    header = 0,\n",
    "    quotechar = \"\\\"\"\n",
    ")\n",
    "test_x = test[[\"age\", \"duration\", \"campaign\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stackingの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データをK個にグループ分け\n",
    "K = 5\n",
    "\n",
    "# 乱数シード設定\n",
    "np.random.seed(seed = 17)\n",
    "\n",
    "train_x[\"cv_group\"] = np.random.randint(\n",
    "    # low以上high未満の整数をsize数だけ生成する\n",
    "    low = 0, high = K, size = train_x.shape[0]).tolist()\n",
    "train_y[\"cv_group\"] = train_x[\"cv_group\"]\n",
    "\n",
    "# CV内での構築, 検証予測スコアの初期化\n",
    "pred_train_tree = list()\n",
    "pred_train_logi = list()\n",
    "pred_test_tree = np.zeros(test_x.shape[0]) \n",
    "pred_test_logi = np.zeros(test_x.shape[0]) \n",
    "m_train_y = list()\n",
    "\n",
    "# クロスバリデーション\n",
    "for i in range(K):\n",
    "    # 分割\n",
    "    train_x_tmp = train_x[train_x[\"cv_group\"] != i]\n",
    "    train_y_tmp = train_y[train_y[\"cv_group\"] != i]\n",
    "    valid_x_tmp = train_x[train_x[\"cv_group\"] == i]\n",
    "    valid_y_tmp = train_y[train_y[\"cv_group\"] == i]\n",
    "    \n",
    "    del train_x_tmp[\"cv_group\"]\n",
    "    del train_y_tmp[\"cv_group\"]\n",
    "    del valid_x_tmp[\"cv_group\"]\n",
    "    del valid_y_tmp[\"cv_group\"]\n",
    "    \n",
    "    # 決定木構築\n",
    "    tree_model_tmp = DecisionTreeClassifier(\n",
    "        random_state = 17,\n",
    "        criterion = \"gini\",             # Entropy基準の場合は\"entropy”\n",
    "        splitter = \"best\",              # 分割をランダムで行う場合は\"random\"\n",
    "        max_depth = 7,                  # 決定木の深さの最大値\n",
    "        min_samples_split = 20          # 分割する最小データ数\n",
    "    )\n",
    "    tree_model_tmp.fit(train_x_tmp, train_y_tmp)\n",
    "    \n",
    "    # ロジスティック回帰構築\n",
    "    Logi_model_tmp = LogisticRegression(solver=\"liblinear\")\n",
    "    Logi_model_tmp.fit(train_x_tmp, train_y_tmp[\"y\"])\n",
    "    \n",
    "    # モデル構築に使用していないデータの予測値と目的変数\n",
    "    pred_train_tree.extend(tree_model_tmp.predict_proba(valid_x_tmp)[:, 1].tolist())\n",
    "    pred_train_logi.extend(Logi_model_tmp.predict_proba(valid_x_tmp)[:, 1].tolist())\n",
    "    m_train_y.extend(valid_y_tmp[\"y\"].tolist())\n",
    "    \n",
    "    # testデータの予測値\n",
    "    pred_test_tree = pred_test_tree + tree_model_tmp.predict_proba(test_x)[:, 1]\n",
    "    pred_test_logi = pred_test_logi + Logi_model_tmp.predict_proba(test_x)[:, 1]\n",
    "\n",
    "    \n",
    "# testデータの予測値の平均\n",
    "pred_test_tree = pred_test_tree / K\n",
    "pred_test_logi = pred_test_logi / K\n",
    "\n",
    "pred_test_tree = pred_test_tree.tolist()\n",
    "pred_test_logi = pred_test_logi.tolist()\n",
    "\n",
    "\n",
    "# メタモデル用変数\n",
    "m_train_x = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(data = pred_train_tree, columns = [\"pred_tree\"]),\n",
    "        pd.DataFrame(data = pred_train_logi, columns = [\"pred_logi\"])\n",
    "    ],\n",
    "    axis = 1\n",
    ")\n",
    "m_train_y = pd.DataFrame(data = m_train_y, columns = [\"y\"])\n",
    "\n",
    "\n",
    "# メタモデル構築\n",
    "meta_model_2 = LogisticRegression(solver=\"liblinear\")\n",
    "meta_model_2.fit(m_train_x, m_train_y[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証データ適用方法1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メタモデル用変数\n",
    "m_test_x_1 = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(data = pred_test_tree, columns = [\"pred_tree\"]),\n",
    "        pd.DataFrame(data = pred_test_logi, columns = [\"pred_logi\"])\n",
    "    ],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# メタモデルの当てはめ\n",
    "pred_valid_m_1 = meta_model_2.predict_proba(m_test_x_1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_ens = test[[\"id\"]].assign(pred=pred_valid_m_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_ens.to_csv(\n",
    "    \"../submit/submit_tree_logi_ens_20201022.csv\",\n",
    "    sep = \",\",\n",
    "    index = False,\n",
    "    header = False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
